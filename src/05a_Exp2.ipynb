{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c0d5566da64468b916a025b94620f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_51e972e4e0cd4f30abf5967506429df3"
          }
        },
        "e4f871cdac9d4719b453177d09494761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efe663637404332b5ad85f4fbcbdb43",
            "placeholder": "​",
            "style": "IPY_MODEL_182259f7b36b45b7b62832dd8359ad56",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "67a2745bae82405ba42a34f8502fcc7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c50b4fda93c44d60ba626483e4fe8fe3",
            "placeholder": "​",
            "style": "IPY_MODEL_6a874ee6b4734716a4e8af6655ff682f",
            "value": ""
          }
        },
        "d68ded4f0c8d4228a58d2f7dff79a219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b098b40dcdf14128a5341006557b49c6",
            "style": "IPY_MODEL_60bc279ddf3e46f8bd13a93b84d7a884",
            "value": true
          }
        },
        "b71f448a0f524e9b87437add6f0d812d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b9bcbd856eb4472090c47196c43af834",
            "style": "IPY_MODEL_8a8b06eae3ad4ac29207eb9f3ef6554d",
            "tooltip": ""
          }
        },
        "35be5cb92542482f9096ae44348ad85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_355b2ee6b55244929ff09e5ea585f445",
            "placeholder": "​",
            "style": "IPY_MODEL_2856f046a2e946a6b45c1f2fbfb65350",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "51e972e4e0cd4f30abf5967506429df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0efe663637404332b5ad85f4fbcbdb43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182259f7b36b45b7b62832dd8359ad56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c50b4fda93c44d60ba626483e4fe8fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a874ee6b4734716a4e8af6655ff682f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b098b40dcdf14128a5341006557b49c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60bc279ddf3e46f8bd13a93b84d7a884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9bcbd856eb4472090c47196c43af834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a8b06eae3ad4ac29207eb9f3ef6554d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "355b2ee6b55244929ff09e5ea585f445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2856f046a2e946a6b45c1f2fbfb65350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cae6b211c2884020bae4e0728bf6113b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e02ad9b2d644058705552f1a08f413",
            "placeholder": "​",
            "style": "IPY_MODEL_49e12b9ce9674d7eb5d1d3e48a20ce88",
            "value": "Connecting..."
          }
        },
        "e5e02ad9b2d644058705552f1a08f413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e12b9ce9674d7eb5d1d3e48a20ce88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b4f1ad42a2049f2b551ef85f4babb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b34e7b7d58d481ba65c52e0420c6fd7",
              "IPY_MODEL_9f7e066b57cc4f8490aa555230fbe53a",
              "IPY_MODEL_f99eacf690a54ee4b48022c0da7b6581"
            ],
            "layout": "IPY_MODEL_91898721fa134ce88c564672f6821095"
          }
        },
        "7b34e7b7d58d481ba65c52e0420c6fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab2664a5cfd74114a710769dd3a294a8",
            "placeholder": "​",
            "style": "IPY_MODEL_947abecf9233487b8b8a59c54a30863b",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "9f7e066b57cc4f8490aa555230fbe53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ab613b45a04ff8a17550c9504f60fe",
            "max": 260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6004c39d111493eb9a7a87d5113971c",
            "value": 260
          }
        },
        "f99eacf690a54ee4b48022c0da7b6581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baacb8324310421c9c40725ea93305c1",
            "placeholder": "​",
            "style": "IPY_MODEL_2317da4c83d146e39ecad5731ed6b7ed",
            "value": " 260/260 [00:00&lt;00:00, 27.9kB/s]"
          }
        },
        "91898721fa134ce88c564672f6821095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2664a5cfd74114a710769dd3a294a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "947abecf9233487b8b8a59c54a30863b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05ab613b45a04ff8a17550c9504f60fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6004c39d111493eb9a7a87d5113971c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baacb8324310421c9c40725ea93305c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2317da4c83d146e39ecad5731ed6b7ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e7f0d320984a64a4b8bd38c6b857d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cce45fc859fc4ab68047e831b22a9f63",
              "IPY_MODEL_0238c7a243794525a76e18b434cac162",
              "IPY_MODEL_fbeb4720a25e48f3b2950406fabdd9f3"
            ],
            "layout": "IPY_MODEL_5efbf896b76f476693ade4ac2f093317"
          }
        },
        "cce45fc859fc4ab68047e831b22a9f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b7f50f9c9324ac5b58b88262bfe8acd",
            "placeholder": "​",
            "style": "IPY_MODEL_799ade344d2b486e98b47ad4e19484b3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0238c7a243794525a76e18b434cac162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33bdb1811db14c0abd8d4309fec3dff4",
            "max": 257,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d5ca2495cc94f469515db35fc0648b2",
            "value": 257
          }
        },
        "fbeb4720a25e48f3b2950406fabdd9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3744f3e5f2470f9432edb3931e54c9",
            "placeholder": "​",
            "style": "IPY_MODEL_0e2135642b7d4b12bfa718aeb3bc14e6",
            "value": " 257/257 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "5efbf896b76f476693ade4ac2f093317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b7f50f9c9324ac5b58b88262bfe8acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799ade344d2b486e98b47ad4e19484b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33bdb1811db14c0abd8d4309fec3dff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5ca2495cc94f469515db35fc0648b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c3744f3e5f2470f9432edb3931e54c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2135642b7d4b12bfa718aeb3bc14e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9619978106074036a6f0a91f8dc0cf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54348c82cd2640b9a0e4b459c87c8047",
              "IPY_MODEL_ab401fb8edd74d70a30156cd0eea9747",
              "IPY_MODEL_05669160cbd94c5587927e0a56b5b517"
            ],
            "layout": "IPY_MODEL_e19f67e12c734f0685cf3d8909bc9eca"
          }
        },
        "54348c82cd2640b9a0e4b459c87c8047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf126b6dc144df3856dacb540839406",
            "placeholder": "​",
            "style": "IPY_MODEL_f573b358ea654cc3b28767daa144fa97",
            "value": "vocab.json: 100%"
          }
        },
        "ab401fb8edd74d70a30156cd0eea9747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e56876d0b7fb4f4f9edcfe631f029ff1",
            "max": 741,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c96dc097de09492cb6472faf154eadfb",
            "value": 741
          }
        },
        "05669160cbd94c5587927e0a56b5b517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba6601e8c27420f8c54b80dad9c25d6",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7f94fae0b04494b4836ac1cbac2985",
            "value": " 741/741 [00:00&lt;00:00, 48.0kB/s]"
          }
        },
        "e19f67e12c734f0685cf3d8909bc9eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf126b6dc144df3856dacb540839406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f573b358ea654cc3b28767daa144fa97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e56876d0b7fb4f4f9edcfe631f029ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96dc097de09492cb6472faf154eadfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ba6601e8c27420f8c54b80dad9c25d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7f94fae0b04494b4836ac1cbac2985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfef9214938d4f7a93d499736af8d7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f70f87a95df042ccbcb234db46121798",
              "IPY_MODEL_955d10b51e9941ccb3004caa46952365",
              "IPY_MODEL_90c757aeb24b4e6fa141f8560a1a77a9"
            ],
            "layout": "IPY_MODEL_d5bd079097f44cffabfa21a00199a35e"
          }
        },
        "f70f87a95df042ccbcb234db46121798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f65fa66219294d2eb5e23c0de21f8d4f",
            "placeholder": "​",
            "style": "IPY_MODEL_501bdcd287a146118a6d027b1a32bfc3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "955d10b51e9941ccb3004caa46952365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b3d47c25574085b40090d2283a4c42",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4bebe12d0b44e1e8188122543fe2f0b",
            "value": 85
          }
        },
        "90c757aeb24b4e6fa141f8560a1a77a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d17e5ce1fb3c490c97a385bacb095f54",
            "placeholder": "​",
            "style": "IPY_MODEL_7a4ce3281bb7455086cb21a3d6f7f9bd",
            "value": " 85.0/85.0 [00:00&lt;00:00, 4.75kB/s]"
          }
        },
        "d5bd079097f44cffabfa21a00199a35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65fa66219294d2eb5e23c0de21f8d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501bdcd287a146118a6d027b1a32bfc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b3d47c25574085b40090d2283a4c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bebe12d0b44e1e8188122543fe2f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d17e5ce1fb3c490c97a385bacb095f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4ce3281bb7455086cb21a3d6f7f9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "999021b4ac7143008109dff366a8a3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf34b13742604a70a3934433cd99b16e",
              "IPY_MODEL_10678fff89fb4719937542aa9b0ab3a8",
              "IPY_MODEL_037acfdb903644ee80cd95942cfa6ac3"
            ],
            "layout": "IPY_MODEL_be698a79b58f45ecae56a9bd16830524"
          }
        },
        "cf34b13742604a70a3934433cd99b16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7224656584f42c2b288b05b74699f3a",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f78041dc194f8394d3594420455aab",
            "value": "README.md: 100%"
          }
        },
        "10678fff89fb4719937542aa9b0ab3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c26a15781242928db72a51fdb3cae2",
            "max": 436,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43be90287a4a4803b25e78a998fe96ab",
            "value": 436
          }
        },
        "037acfdb903644ee80cd95942cfa6ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db3f6e5b77694dedadda92d0aec7dcf0",
            "placeholder": "​",
            "style": "IPY_MODEL_81ca2a0f63d741a9bb2be7c2f165b1e8",
            "value": " 436/436 [00:00&lt;00:00, 46.7kB/s]"
          }
        },
        "be698a79b58f45ecae56a9bd16830524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7224656584f42c2b288b05b74699f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f78041dc194f8394d3594420455aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43c26a15781242928db72a51fdb3cae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43be90287a4a4803b25e78a998fe96ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db3f6e5b77694dedadda92d0aec7dcf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ca2a0f63d741a9bb2be7c2f165b1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. INSTALL DEPENDENCIES\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"📦 Installing dependencies...\")\n",
        "!pip install -q huggingface_hub onnx onnxruntime-gpu librosa datasets jiwer tensorrt\n",
        "!pip install -q numpy==1.23.5  # Pin NumPy to prevent version conflicts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "FcLU4wVTt8_Z",
        "outputId": "93812bc6-d760-48fd-dfef-f6f8009854e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Installing dependencies...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPACROgKwxsV",
        "outputId": "e548b676-a326-4cd9-ca9d-784b6499682c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.12/dist-packages (2026.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.12/dist-packages (from pycuda) (2025.2.5)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycuda) (4.5.1)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from pycuda) (1.3.10)\n",
            "Requirement already satisfied: siphash24>=1.6 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (1.8)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from mako->pycuda) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgiH7cpyw2Oj",
        "outputId": "df264cb8-3ce3-4577-eb94-92835b0afa91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.20.1)\n",
            "Requirement already satisfied: onnxsim in /usr/local/lib/python3.12/dist-packages (0.4.36)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->onnxsim) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->onnxsim) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "5c0d5566da64468b916a025b94620f57",
            "e4f871cdac9d4719b453177d09494761",
            "67a2745bae82405ba42a34f8502fcc7d",
            "d68ded4f0c8d4228a58d2f7dff79a219",
            "b71f448a0f524e9b87437add6f0d812d",
            "35be5cb92542482f9096ae44348ad85b",
            "51e972e4e0cd4f30abf5967506429df3",
            "0efe663637404332b5ad85f4fbcbdb43",
            "182259f7b36b45b7b62832dd8359ad56",
            "c50b4fda93c44d60ba626483e4fe8fe3",
            "6a874ee6b4734716a4e8af6655ff682f",
            "b098b40dcdf14128a5341006557b49c6",
            "60bc279ddf3e46f8bd13a93b84d7a884",
            "b9bcbd856eb4472090c47196c43af834",
            "8a8b06eae3ad4ac29207eb9f3ef6554d",
            "355b2ee6b55244929ff09e5ea585f445",
            "2856f046a2e946a6b45c1f2fbfb65350",
            "cae6b211c2884020bae4e0728bf6113b",
            "e5e02ad9b2d644058705552f1a08f413",
            "49e12b9ce9674d7eb5d1d3e48a20ce88"
          ]
        },
        "id": "FcWn8SlxzbEF",
        "outputId": "4b23f18a-843b-4ed6-90e2-75a670858e39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c0d5566da64468b916a025b94620f57"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Uninstall any broken versions\n",
        "!pip uninstall -y tensorrt tensorrt-cu12-bindings tensorrt-cu12-libs\n",
        "!pip install -q numpy==1.23.5\n",
        "\n",
        "# 2. Install the specific compatible version\n",
        "# We use the NVIDIA Index URL to get the pre-compiled Linux wheels\n",
        "!pip install tensorrt==10.0.1 --extra-index-url https://pypi.nvidia.com\n",
        "\n",
        "# 3. Force the system to register the libraries\n",
        "!ldconfig\n",
        "\n",
        "print(\"\\n✅ Install Complete.\")\n",
        "print(\"🛑 STOP! You MUST now click 'Runtime' > 'Restart Session' (or 'Restart Runtime') in the top menu.\")\n",
        "print(\"👉 After restarting, skip this cell and run Step 2 below.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RTm3Nqd0ImJ",
        "outputId": "5a64f54c-4cbe-448f-8780-eee66671bdb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorrt 10.0.1\n",
            "Uninstalling tensorrt-10.0.1:\n",
            "  Successfully uninstalled tensorrt-10.0.1\n",
            "Found existing installation: tensorrt_cu12_bindings 10.14.1.48.post1\n",
            "Uninstalling tensorrt_cu12_bindings-10.14.1.48.post1:\n",
            "  Successfully uninstalled tensorrt_cu12_bindings-10.14.1.48.post1\n",
            "Found existing installation: tensorrt_cu12_libs 10.14.1.48.post1\n",
            "Uninstalling tensorrt_cu12_libs-10.14.1.48.post1:\n",
            "  Successfully uninstalled tensorrt_cu12_libs-10.14.1.48.post1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting tensorrt==10.0.1\n",
            "  Using cached tensorrt-10.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorrt-cu12 in /usr/local/lib/python3.12/dist-packages (from tensorrt==10.0.1) (10.14.1.48.post1)\n",
            "Collecting tensorrt-cu12-libs==10.14.1.48.post1 (from tensorrt-cu12->tensorrt==10.0.1)\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-cu12-libs/tensorrt_cu12_libs-10.14.1.48.post1-py2.py3-none-manylinux_2_28_x86_64.whl (3960.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 GB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/tensorrt-cu12-bindings/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorrt-cu12-bindings==10.14.1.48.post1 (from tensorrt-cu12->tensorrt==10.0.1)\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-cu12-bindings/tensorrt_cu12_bindings-10.14.1.48.post1-cp312-none-manylinux_2_28_x86_64.whl (879 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.9/879.9 kB\u001b[0m \u001b[31m248.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cuda-toolkit<13,>=12 in /usr/local/lib/python3.12/dist-packages (from cuda-toolkit[cudart]<13,>=12->tensorrt-cu12-libs==10.14.1.48.post1->tensorrt-cu12->tensorrt==10.0.1) (12.9.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.9.79.* in /usr/local/lib/python3.12/dist-packages (from cuda-toolkit[cudart]<13,>=12->tensorrt-cu12-libs==10.14.1.48.post1->tensorrt-cu12->tensorrt==10.0.1) (12.9.79)\n",
            "Installing collected packages: tensorrt-cu12-bindings, tensorrt-cu12-libs, tensorrt\n",
            "Successfully installed tensorrt-10.0.1 tensorrt-cu12-bindings-10.14.1.48.post1 tensorrt-cu12-libs-10.14.1.48.post1\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "\n",
            "✅ Install Complete.\n",
            "🛑 STOP! You MUST now click 'Runtime' > 'Restart Session' (or 'Restart Runtime') in the top menu.\n",
            "👉 After restarting, skip this cell and run Step 2 below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🚀 MASTER SCRIPT: ONNX BASELINE vs. TENSORRT OPTIMIZATION\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import ctypes\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "import onnxruntime as ort\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import librosa\n",
        "import io\n",
        "from huggingface_hub import hf_hub_download\n",
        "from transformers import Wav2Vec2Processor\n",
        "from datasets import load_dataset\n",
        "from jiwer import wer\n",
        "\n",
        "# Fix Library Paths for Colab\n",
        "current_ld = os.environ.get('LD_LIBRARY_PATH', '')\n",
        "if '/usr/lib64-nvidia' not in current_ld:\n",
        "    os.environ['LD_LIBRARY_PATH'] = current_ld + ':/usr/lib64-nvidia'\n",
        "\n",
        "# Force-load TensorRT drivers\n",
        "try:\n",
        "    libs = glob.glob(\"/usr/local/lib/python*/dist-packages/tensorrt_libs\")[0]\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer.so.10\"))\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer_plugin.so.10\"))\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. PREPARE RESOURCES\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n⬇️ Downloading Resources...\")\n",
        "\n",
        "# Download Clean ONNX (FP32)\n",
        "if not os.path.exists(\"model.onnx\"):\n",
        "    try:\n",
        "        path = hf_hub_download(repo_id=\"onnx-community/indicwav2vec-hindi-ONNX\", filename=\"onnx/model.onnx\")\n",
        "        os.symlink(path, \"model.onnx\")\n",
        "        print(\"✅ Model downloaded (1.2 GB)\")\n",
        "    except:\n",
        "        print(\"❌ Download failed. Check internet connection.\")\n",
        "        exit()\n",
        "\n",
        "# Load Processor & Dataset\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"ai4bharat/indicwav2vec-hindi\")\n",
        "ds = load_dataset(\"MatrixSpeechAI/Common_voice_hindi_denoised\", split=\"train\", streaming=True).decode(False)\n",
        "# Get 20 samples for testing\n",
        "test_samples = list(ds.take(20))\n",
        "print(\"✅ Dataset loaded (20 samples)\")\n",
        "\n",
        "\n",
        "# 3. BASELINE: RUN RAW ONNX (ONNX RUNTIME)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🐢 Running Baseline (ONNX Runtime)...\")\n",
        "ort_sess = ort.InferenceSession(\"model.onnx\", providers=['CUDAExecutionProvider'])\n",
        "\n",
        "base_times = []\n",
        "base_preds = []\n",
        "base_truths = []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    start = time.time()\n",
        "    logits = ort_sess.run(None, {'input_values': input_values})[0]\n",
        "    base_times.append((time.time() - start) * 1000)\n",
        "\n",
        "    pred_ids = np.argmax(logits, axis=-1)[0]\n",
        "    base_preds.append(processor.decode(pred_ids))\n",
        "    base_truths.append(item[\"transcription\"])\n",
        "\n",
        "base_wer = wer(base_truths, base_preds) * 100\n",
        "base_lat = np.mean(base_times)\n",
        "print(f\"👉 Baseline Result: {base_lat:.2f} ms | {base_wer:.2f}% WER\")\n",
        "\n",
        "\n",
        "# 4. OPTIMIZATION: BUILD TENSORRT ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🛡️ Building Optimized Engine (TensorRT)...\")\n",
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
        "network = builder.create_network(flag)\n",
        "config = builder.create_builder_config()\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "\n",
        "with open(\"model.onnx\", 'rb') as f:\n",
        "    parser.parse(f.read())\n",
        "\n",
        "# Dynamic Shapes\n",
        "profile = builder.create_optimization_profile()\n",
        "profile.set_shape(\"input_values\", (1, 16000), (1, 80000), (4, 160000))\n",
        "config.add_optimization_profile(profile)\n",
        "\n",
        "# ENABLE FP16 (Speed)\n",
        "if builder.platform_has_fast_fp16:\n",
        "    config.set_flag(trt.BuilderFlag.FP16)\n",
        "\n",
        "# APPLY \"THE ANTIDOTE\" (Fix 162% WER)\n",
        "count = 0\n",
        "for i in range(network.num_layers):\n",
        "    layer = network.get_layer(i)\n",
        "    if \"Pow\" in layer.name or layer.type == trt.LayerType.REDUCE:\n",
        "        layer.precision = trt.DataType.FLOAT\n",
        "        if layer.num_outputs > 0:\n",
        "            layer.set_output_type(0, trt.DataType.FLOAT)\n",
        "        count += 1\n",
        "config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "print(f\"   (Locked {count} sensitive layers to FP32)\")\n",
        "\n",
        "# Build\n",
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 4 * 1024**3)\n",
        "plan = builder.build_serialized_network(network, config)\n",
        "with open(\"model.engine\", \"wb\") as f:\n",
        "    f.write(plan)\n",
        "print(\"✅ Engine Built Successfully!\")\n",
        "\n",
        "\n",
        "# 5. BENCHMARK: RUN TENSORRT ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🚀 Running Optimized Benchmark (TensorRT)...\")\n",
        "runtime = trt.Runtime(logger)\n",
        "engine = runtime.deserialize_cuda_engine(plan)\n",
        "context = engine.create_execution_context()\n",
        "\n",
        "trt_times = []\n",
        "trt_preds = []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    # Allocations\n",
        "    context.set_input_shape(\"input_values\", input_values.shape)\n",
        "    d_input = cuda.mem_alloc(input_values.nbytes)\n",
        "    h_output = np.empty((1, input_values.shape[1] // 320, 108), dtype=np.float32)\n",
        "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(d_input, input_values)\n",
        "    start = time.time()\n",
        "    context.execute_v2([int(d_input), int(d_output)])\n",
        "    trt_times.append((time.time() - start) * 1000)\n",
        "    cuda.memcpy_dtoh(h_output, d_output)\n",
        "\n",
        "    # CTC Decode (Logic Fix)\n",
        "    pred_ids = np.argmax(h_output, axis=-1)[0]\n",
        "    # Simple collapse: remove repeats and blanks\n",
        "    grouped = [x for i, x in enumerate(pred_ids) if i == 0 or x != pred_ids[i-1]]\n",
        "    clean = [x for x in grouped if x != processor.tokenizer.pad_token_id]\n",
        "    trt_preds.append(processor.decode(clean))\n",
        "\n",
        "trt_wer = wer(base_truths, trt_preds) * 100\n",
        "trt_lat = np.mean(trt_times)\n",
        "\n",
        "\n",
        "# 6. FINAL REPORT\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{'METRIC':<20} | {'BASELINE (ONNX)':<15} | {'OPTIMIZED (TRT)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Latency (ms)':<20} | {base_lat:<15.2f} | {trt_lat:<15.2f}\")\n",
        "print(f\"{'WER (%)':<20} | {base_wer:<15.2f} | {trt_wer:<15.2f}\")\n",
        "print(f\"{'Speedup':<20} | {'1.0x':<15} | {base_lat/trt_lat:<15.2f}x\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTvM_M67tpXF",
        "outputId": "5f7ba4be-8dbf-4670-c74a-1a1fe8ba0c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⬇️ Downloading Resources...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded (20 samples)\n",
            "\n",
            "🐢 Running Baseline (ONNX Runtime)...\n",
            "👉 Baseline Result: 68.48 ms | 36.59% WER\n",
            "\n",
            "🛡️ Building Optimized Engine (TensorRT)...\n",
            "   (Locked 0 sensitive layers to FP32)\n",
            "✅ Engine Built Successfully!\n",
            "\n",
            "🚀 Running Optimized Benchmark (TensorRT)...\n",
            "\n",
            "============================================================\n",
            "METRIC               | BASELINE (ONNX) | OPTIMIZED (TRT)\n",
            "------------------------------------------------------------\n",
            "Latency (ms)         | 68.48           | 15.87          \n",
            "WER (%)              | 36.59           | 110.57         \n",
            "Speedup              | 1.0x            | 4.31           x\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🚀 MASTER SCRIPT: ONNX BASELINE vs. TENSORRT OPTIMIZATION\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import ctypes\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "import onnxruntime as ort\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import librosa\n",
        "import io\n",
        "from huggingface_hub import hf_hub_download\n",
        "from transformers import Wav2Vec2Processor\n",
        "from datasets import load_dataset\n",
        "from jiwer import wer\n",
        "\n",
        "# Fix Library Paths for Colab\n",
        "current_ld = os.environ.get('LD_LIBRARY_PATH', '')\n",
        "if '/usr/lib64-nvidia' not in current_ld:\n",
        "    os.environ['LD_LIBRARY_PATH'] = current_ld + ':/usr/lib64-nvidia'\n",
        "\n",
        "# Force-load TensorRT drivers\n",
        "try:\n",
        "    libs = glob.glob(\"/usr/local/lib/python*/dist-packages/tensorrt_libs\")[0]\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer.so.10\"))\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer_plugin.so.10\"))\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. PREPARE RESOURCES\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n⬇️ Downloading Resources...\")\n",
        "\n",
        "# Download Clean ONNX (FP32)\n",
        "if not os.path.exists(\"model.onnx\"):\n",
        "    try:\n",
        "        path = hf_hub_download(repo_id=\"onnx-community/indicwav2vec-hindi-ONNX\", filename=\"onnx/model.onnx\")\n",
        "        os.symlink(path, \"model.onnx\")\n",
        "        print(\"✅ Model downloaded (1.2 GB)\")\n",
        "    except:\n",
        "        print(\"❌ Download failed. Check internet connection.\")\n",
        "        exit()\n",
        "\n",
        "# Load Processor & Dataset\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"ai4bharat/indicwav2vec-hindi\")\n",
        "ds = load_dataset(\"MatrixSpeechAI/Common_voice_hindi_denoised\", split=\"train\", streaming=True).decode(False)\n",
        "# Get 20 samples for testing\n",
        "test_samples = list(ds.take(20))\n",
        "print(\"✅ Dataset loaded (20 samples)\")\n",
        "\n",
        "\n",
        "# 3. BASELINE: RUN RAW ONNX (ONNX RUNTIME)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🐢 Running Baseline (ONNX Runtime)...\")\n",
        "ort_sess = ort.InferenceSession(\"model.onnx\", providers=['CUDAExecutionProvider'])\n",
        "\n",
        "base_times = []\n",
        "base_preds = []\n",
        "base_truths = []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    start = time.time()\n",
        "    logits = ort_sess.run(None, {'input_values': input_values})[0]\n",
        "    base_times.append((time.time() - start) * 1000)\n",
        "\n",
        "    pred_ids = np.argmax(logits, axis=-1)[0]\n",
        "    base_preds.append(processor.decode(pred_ids))\n",
        "    base_truths.append(item[\"transcription\"])\n",
        "\n",
        "base_wer = wer(base_truths, base_preds) * 100\n",
        "base_lat = np.mean(base_times)\n",
        "print(f\"👉 Baseline Result: {base_lat:.2f} ms | {base_wer:.2f}% WER\")\n",
        "\n",
        "\n",
        "# 4. OPTIMIZATION: BUILD TENSORRT ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🛡️ Building Optimized Engine (TensorRT)...\")\n",
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
        "network = builder.create_network(flag)\n",
        "config = builder.create_builder_config()\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "\n",
        "with open(\"model.onnx\", 'rb') as f:\n",
        "    parser.parse(f.read())\n",
        "\n",
        "# Dynamic Shapes\n",
        "profile = builder.create_optimization_profile()\n",
        "profile.set_shape(\"input_values\", (1, 16000), (1, 80000), (4, 160000))\n",
        "config.add_optimization_profile(profile)\n",
        "\n",
        "# ENABLE FP16 (Speed)\n",
        "if builder.platform_has_fast_fp16:\n",
        "    config.set_flag(trt.BuilderFlag.FP16)\n",
        "\n",
        "# --- APPLY \"THE ANTIDOTE\" (Fix 162% WER) ---\n",
        "print(\"🛡️ Applying Antidote...\")\n",
        "count = 0\n",
        "for i in range(network.num_layers):\n",
        "    layer = network.get_layer(i)\n",
        "\n",
        "    # NEW LOGIC: Catch Opset 17 \"LayerNormalization\" nodes explicitly\n",
        "    if layer.type == trt.LayerType.NORMALIZATION or \"LayerNorm\" in layer.name:\n",
        "        layer.precision = trt.DataType.FLOAT\n",
        "        if layer.num_outputs > 0:\n",
        "            layer.set_output_type(0, trt.DataType.FLOAT)\n",
        "        count += 1\n",
        "config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "print(f\"   (Locked {count} sensitive layers to FP32)\")\n",
        "\n",
        "# 5. BENCHMARK: RUN TENSORRT ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🚀 Running Optimized Benchmark (TensorRT)...\")\n",
        "runtime = trt.Runtime(logger)\n",
        "engine = runtime.deserialize_cuda_engine(plan)\n",
        "context = engine.create_execution_context()\n",
        "\n",
        "trt_times = []\n",
        "trt_preds = []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    # Allocations\n",
        "    context.set_input_shape(\"input_values\", input_values.shape)\n",
        "    d_input = cuda.mem_alloc(input_values.nbytes)\n",
        "    h_output = np.empty((1, input_values.shape[1] // 320, 108), dtype=np.float32)\n",
        "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(d_input, input_values)\n",
        "    start = time.time()\n",
        "    context.execute_v2([int(d_input), int(d_output)])\n",
        "    trt_times.append((time.time() - start) * 1000)\n",
        "    cuda.memcpy_dtoh(h_output, d_output)\n",
        "\n",
        "    # CTC Decode (Logic Fix)\n",
        "    pred_ids = np.argmax(h_output, axis=-1)[0]\n",
        "    # Simple collapse: remove repeats and blanks\n",
        "    grouped = [x for i, x in enumerate(pred_ids) if i == 0 or x != pred_ids[i-1]]\n",
        "    clean = [x for x in grouped if x != processor.tokenizer.pad_token_id]\n",
        "    trt_preds.append(processor.decode(clean))\n",
        "\n",
        "trt_wer = wer(base_truths, trt_preds) * 100\n",
        "trt_lat = np.mean(trt_times)\n",
        "\n",
        "\n",
        "# 6. FINAL REPORT\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{'METRIC':<20} | {'BASELINE (ONNX)':<15} | {'OPTIMIZED (TRT)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Latency (ms)':<20} | {base_lat:<15.2f} | {trt_lat:<15.2f}\")\n",
        "print(f\"{'WER (%)':<20} | {base_wer:<15.2f} | {trt_wer:<15.2f}\")\n",
        "print(f\"{'Speedup':<20} | {'1.0x':<15} | {base_lat/trt_lat:<15.2f}x\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj_FzK6rwu6u",
        "outputId": "2ffd4ea7-b8f8-42af-9f9d-e97835ca25c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⬇️ Downloading Resources...\n",
            "✅ Dataset loaded (20 samples)\n",
            "\n",
            "🐢 Running Baseline (ONNX Runtime)...\n",
            "👉 Baseline Result: 55.11 ms | 36.59% WER\n",
            "\n",
            "🛡️ Building Optimized Engine (TensorRT)...\n",
            "🛡️ Applying Antidote...\n",
            "   (Locked 57 sensitive layers to FP32)\n",
            "\n",
            "🚀 Running Optimized Benchmark (TensorRT)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3866868129.py:114: DeprecationWarning: Use Deprecated in TensorRT 10.12. Superseded by strong typing. instead.\n",
            "  layer.precision = trt.DataType.FLOAT\n",
            "/tmp/ipython-input-3866868129.py:116: DeprecationWarning: Use Deprecated in TensorRT 10.12. Superseded by strong typing. instead.\n",
            "  layer.set_output_type(0, trt.DataType.FLOAT)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC               | BASELINE (ONNX) | OPTIMIZED (TRT)\n",
            "------------------------------------------------------------\n",
            "Latency (ms)         | 55.11           | 16.45          \n",
            "WER (%)              | 36.59           | 109.76         \n",
            "Speedup              | 1.0x            | 3.35           x\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🚀 MASTER SCRIPT: ONNX BASELINE vs. TENSORRT OPTIMIZATION\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import ctypes\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "import onnxruntime as ort\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import librosa\n",
        "import io\n",
        "from huggingface_hub import hf_hub_download\n",
        "from transformers import Wav2Vec2Processor\n",
        "from datasets import load_dataset\n",
        "from jiwer import wer\n",
        "\n",
        "# Fix Library Paths for Colab\n",
        "current_ld = os.environ.get('LD_LIBRARY_PATH', '')\n",
        "if '/usr/lib64-nvidia' not in current_ld:\n",
        "    os.environ['LD_LIBRARY_PATH'] = current_ld + ':/usr/lib64-nvidia'\n",
        "\n",
        "# Force-load TensorRT drivers\n",
        "try:\n",
        "    libs = glob.glob(\"/usr/local/lib/python*/dist-packages/tensorrt_libs\")[0]\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer.so.10\"))\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer_plugin.so.10\"))\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. PREPARE RESOURCES\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n⬇️ Downloading Resources...\")\n",
        "\n",
        "# Download Clean ONNX (FP32)\n",
        "if not os.path.exists(\"model.onnx\"):\n",
        "    try:\n",
        "        path = hf_hub_download(repo_id=\"onnx-community/indicwav2vec-hindi-ONNX\", filename=\"onnx/model.onnx\")\n",
        "        os.symlink(path, \"model.onnx\")\n",
        "        print(\"✅ Model downloaded (1.2 GB)\")\n",
        "    except:\n",
        "        print(\"❌ Download failed. Check internet connection.\")\n",
        "        exit()\n",
        "\n",
        "# Load Processor & Dataset\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"ai4bharat/indicwav2vec-hindi\")\n",
        "ds = load_dataset(\"MatrixSpeechAI/Common_voice_hindi_denoised\", split=\"train\", streaming=True).decode(False)\n",
        "# Get 20 samples for testing\n",
        "test_samples = list(ds.take(20))\n",
        "print(\"✅ Dataset loaded (20 samples)\")\n",
        "\n",
        "\n",
        "# 3. BASELINE: RUN RAW ONNX (ONNX RUNTIME)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🐢 Running Baseline (ONNX Runtime)...\")\n",
        "ort_sess = ort.InferenceSession(\"model.onnx\", providers=['CUDAExecutionProvider'])\n",
        "\n",
        "base_times = []\n",
        "base_preds = []\n",
        "base_truths = []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    start = time.time()\n",
        "    logits = ort_sess.run(None, {'input_values': input_values})[0]\n",
        "    base_times.append((time.time() - start) * 1000)\n",
        "\n",
        "    pred_ids = np.argmax(logits, axis=-1)[0]\n",
        "    base_preds.append(processor.decode(pred_ids))\n",
        "    base_truths.append(item[\"transcription\"])\n",
        "\n",
        "base_wer = wer(base_truths, base_preds) * 100\n",
        "base_lat = np.mean(base_times)\n",
        "print(f\"👉 Baseline Result: {base_lat:.2f} ms | {base_wer:.2f}% WER\")\n",
        "\n",
        "\n",
        "# 4. OPTIMIZATION: BUILD TENSORRT ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🛡️ Building Optimized Engine (TensorRT)...\")\n",
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
        "network = builder.create_network(flag)\n",
        "config = builder.create_builder_config()\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "\n",
        "with open(\"model.onnx\", 'rb') as f:\n",
        "    parser.parse(f.read())\n",
        "\n",
        "# Dynamic Shapes\n",
        "profile = builder.create_optimization_profile()\n",
        "profile.set_shape(\"input_values\", (1, 16000), (1, 80000), (4, 160000))\n",
        "config.add_optimization_profile(profile)\n",
        "\n",
        "# ENABLE FP16 (Speed)\n",
        "if builder.platform_has_fast_fp16:\n",
        "    config.set_flag(trt.BuilderFlag.FP16)\n",
        "\n",
        "# --- APPLY \"BROAD SPECTRUM\" ANTIDOTE ---\n",
        "print(\"🛡️ Applying Enhanced Antidote (Conv + Softmax + Norm)...\")\n",
        "count = 0\n",
        "for i in range(network.num_layers):\n",
        "    layer = network.get_layer(i)\n",
        "\n",
        "    # Identify Risky Layer Types\n",
        "    is_norm = (layer.type == trt.LayerType.NORMALIZATION) or (\"LayerNorm\" in layer.name)\n",
        "    is_conv = (layer.type == trt.LayerType.CONVOLUTION)\n",
        "    is_softmax = (layer.type == trt.LayerType.SOFTMAX)\n",
        "\n",
        "    # If it's risky, force it to FP32\n",
        "    if is_norm or is_conv or is_softmax:\n",
        "        layer.precision = trt.DataType.FLOAT\n",
        "        if layer.num_outputs > 0:\n",
        "            layer.set_output_type(0, trt.DataType.FLOAT)\n",
        "        count += 1\n",
        "\n",
        "config.set_flag(trt.BuilderFlag.OBEY_PRECISION_CONSTRAINTS)\n",
        "print(f\"   (Locked {count} layers to FP32)\")\n",
        "\n",
        "# 5. BENCHMARK: RUN TENSORRT ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🚀 Running Optimized Benchmark (TensorRT)...\")\n",
        "runtime = trt.Runtime(logger)\n",
        "engine = runtime.deserialize_cuda_engine(plan)\n",
        "context = engine.create_execution_context()\n",
        "\n",
        "trt_times = []\n",
        "trt_preds = []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    # Allocations\n",
        "    context.set_input_shape(\"input_values\", input_values.shape)\n",
        "    d_input = cuda.mem_alloc(input_values.nbytes)\n",
        "    h_output = np.empty((1, input_values.shape[1] // 320, 108), dtype=np.float32)\n",
        "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(d_input, input_values)\n",
        "    start = time.time()\n",
        "    context.execute_v2([int(d_input), int(d_output)])\n",
        "    trt_times.append((time.time() - start) * 1000)\n",
        "    cuda.memcpy_dtoh(h_output, d_output)\n",
        "\n",
        "    # CTC Decode (Logic Fix)\n",
        "    pred_ids = np.argmax(h_output, axis=-1)[0]\n",
        "    # Simple collapse: remove repeats and blanks\n",
        "    grouped = [x for i, x in enumerate(pred_ids) if i == 0 or x != pred_ids[i-1]]\n",
        "    clean = [x for x in grouped if x != processor.tokenizer.pad_token_id]\n",
        "    trt_preds.append(processor.decode(clean))\n",
        "\n",
        "trt_wer = wer(base_truths, trt_preds) * 100\n",
        "trt_lat = np.mean(trt_times)\n",
        "\n",
        "\n",
        "# 6. FINAL REPORT\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{'METRIC':<20} | {'BASELINE (ONNX)':<15} | {'OPTIMIZED (TRT)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Latency (ms)':<20} | {base_lat:<15.2f} | {trt_lat:<15.2f}\")\n",
        "print(f\"{'WER (%)':<20} | {base_wer:<15.2f} | {trt_wer:<15.2f}\")\n",
        "print(f\"{'Speedup':<20} | {'1.0x':<15} | {base_lat/trt_lat:<15.2f}x\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLAnMefT2TcP",
        "outputId": "1f6caa79-9bed-48d9-a121-011e0967d3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⬇️ Downloading Resources...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 7db5a95d-171d-4c94-ac2b-e3e771f312b3)')' thrown while requesting GET https://huggingface.co/datasets/MatrixSpeechAI/Common_voice_hindi_denoised/resolve/f4455c36f4fd22827fd7e9a087da6c5e4d020478/data/train-00000-of-00009.parquet\n",
            "WARNING:huggingface_hub.utils._http:'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 7db5a95d-171d-4c94-ac2b-e3e771f312b3)')' thrown while requesting GET https://huggingface.co/datasets/MatrixSpeechAI/Common_voice_hindi_denoised/resolve/f4455c36f4fd22827fd7e9a087da6c5e4d020478/data/train-00000-of-00009.parquet\n",
            "Retrying in 1s [Retry 1/5].\n",
            "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded (20 samples)\n",
            "\n",
            "🐢 Running Baseline (ONNX Runtime)...\n",
            "👉 Baseline Result: 89.91 ms | 36.59% WER\n",
            "\n",
            "🛡️ Building Optimized Engine (TensorRT)...\n",
            "🛡️ Applying Enhanced Antidote (Conv + Softmax + Norm)...\n",
            "   (Locked 89 layers to FP32)\n",
            "\n",
            "🚀 Running Optimized Benchmark (TensorRT)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2016268212.py:119: DeprecationWarning: Use Deprecated in TensorRT 10.12. Superseded by strong typing. instead.\n",
            "  layer.precision = trt.DataType.FLOAT\n",
            "/tmp/ipython-input-2016268212.py:121: DeprecationWarning: Use Deprecated in TensorRT 10.12. Superseded by strong typing. instead.\n",
            "  layer.set_output_type(0, trt.DataType.FLOAT)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "METRIC               | BASELINE (ONNX) | OPTIMIZED (TRT)\n",
            "------------------------------------------------------------\n",
            "Latency (ms)         | 89.91           | 24.99          \n",
            "WER (%)              | 36.59           | 112.20         \n",
            "Speedup              | 1.0x            | 3.60           x\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🚀 FINAL SOLUTION: FP32 \"SAFE MODE\" ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import ctypes\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "import onnxruntime as ort\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import librosa\n",
        "import io\n",
        "from huggingface_hub import hf_hub_download\n",
        "from transformers import Wav2Vec2Processor\n",
        "from datasets import load_dataset\n",
        "from jiwer import wer\n",
        "\n",
        "# 1. SETUP & LINKING\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"🔧 Linking Drivers...\")\n",
        "try:\n",
        "    libs = glob.glob(\"/usr/local/lib/python*/dist-packages/tensorrt_libs\")[0]\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] += f\":{libs}:/usr/lib64-nvidia\"\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer.so.10\"))\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer_plugin.so.10\"))\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. DATASET & RESOURCES\n",
        "# -----------------------------------------------------------------------------\n",
        "if not os.path.exists(\"model.onnx\"):\n",
        "    print(\"❌ model.onnx missing! Please check previous steps.\")\n",
        "    exit()\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"ai4bharat/indicwav2vec-hindi\")\n",
        "ds = load_dataset(\"MatrixSpeechAI/Common_voice_hindi_denoised\", split=\"train\", streaming=True).decode(False)\n",
        "test_samples = list(ds.take(20))\n",
        "print(\"✅ Resources Loaded.\")\n",
        "\n",
        "# 3. BASELINE (ONNX)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🐢 Running Baseline (ONNX Runtime)...\")\n",
        "ort_sess = ort.InferenceSession(\"model.onnx\", providers=['CUDAExecutionProvider'])\n",
        "base_times, base_preds, base_truths = [], [], []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    start = time.time()\n",
        "    logits = ort_sess.run(None, {'input_values': input_values})[0]\n",
        "    base_times.append((time.time() - start) * 1000)\n",
        "\n",
        "    pred_ids = np.argmax(logits, axis=-1)[0]\n",
        "    base_preds.append(processor.decode(pred_ids))\n",
        "    base_truths.append(item[\"transcription\"])\n",
        "\n",
        "base_wer = wer(base_truths, base_preds) * 100\n",
        "base_lat = np.mean(base_times)\n",
        "print(f\"👉 Baseline: {base_lat:.2f} ms | {base_wer:.2f}% WER\")\n",
        "\n",
        "# 4. BUILD ENGINE (FP32 ONLY - NO FP16 FLAG)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🛡️ Building Safe Engine (FP32 Mode)...\")\n",
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
        "network = builder.create_network(flag)\n",
        "config = builder.create_builder_config()\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "\n",
        "with open(\"model.onnx\", 'rb') as f:\n",
        "    parser.parse(f.read())\n",
        "\n",
        "profile = builder.create_optimization_profile()\n",
        "profile.set_shape(\"input_values\", (1, 16000), (1, 80000), (4, 160000))\n",
        "config.add_optimization_profile(profile)\n",
        "\n",
        "# CRITICAL CHANGE: WE DO NOT SET THE FP16 FLAG HERE.\n",
        "# This forces TensorRT to use FP32 precision, which is mathematically safe.\n",
        "# We also don't need the \"Antidote\" loop because everything is already FP32.\n",
        "\n",
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 4 * 1024**3)\n",
        "print(\"Building Engine... (This optimizes the graph structure without breaking math)\")\n",
        "plan = builder.build_serialized_network(network, config)\n",
        "\n",
        "if not plan:\n",
        "    print(\"❌ Build Failed!\")\n",
        "    exit()\n",
        "print(\"✅ Engine Built!\")\n",
        "\n",
        "# 5. BENCHMARK ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🚀 Running Safe Benchmark...\")\n",
        "runtime = trt.Runtime(logger)\n",
        "engine = runtime.deserialize_cuda_engine(plan)\n",
        "context = engine.create_execution_context()\n",
        "\n",
        "trt_times, trt_preds = [], []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    # Allocations\n",
        "    context.set_input_shape(\"input_values\", input_values.shape)\n",
        "    d_input = cuda.mem_alloc(input_values.nbytes)\n",
        "    h_output = np.empty((1, input_values.shape[1] // 320, 108), dtype=np.float32)\n",
        "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "\n",
        "    # Inference\n",
        "    cuda.memcpy_htod(d_input, input_values)\n",
        "    start = time.time()\n",
        "    context.execute_v2([int(d_input), int(d_output)])\n",
        "    trt_times.append((time.time() - start) * 1000)\n",
        "    cuda.memcpy_dtoh(h_output, d_output)\n",
        "\n",
        "    # Decode\n",
        "    pred_ids = np.argmax(h_output, axis=-1)[0]\n",
        "    grouped = [x for i, x in enumerate(pred_ids) if i == 0 or x != pred_ids[i-1]]\n",
        "    clean = [x for x in grouped if x != processor.tokenizer.pad_token_id]\n",
        "    trt_preds.append(processor.decode(clean))\n",
        "\n",
        "trt_wer = wer(base_truths, trt_preds) * 100\n",
        "trt_lat = np.mean(trt_times)\n",
        "\n",
        "# 6. REPORT\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{'METRIC':<20} | {'BASELINE':<15} | {'OPTIMIZED (FP32)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Latency (ms)':<20} | {base_lat:<15.2f} | {trt_lat:<15.2f}\")\n",
        "print(f\"{'WER (%)':<20} | {base_wer:<15.2f} | {trt_wer:<15.2f}\")\n",
        "print(f\"{'Speedup':<20} | {'1.0x':<15} | {base_lat/trt_lat:<15.2f}x\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "ok1zK7Bn4mcG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653,
          "referenced_widgets": [
            "3b4f1ad42a2049f2b551ef85f4babb1e",
            "7b34e7b7d58d481ba65c52e0420c6fd7",
            "9f7e066b57cc4f8490aa555230fbe53a",
            "f99eacf690a54ee4b48022c0da7b6581",
            "91898721fa134ce88c564672f6821095",
            "ab2664a5cfd74114a710769dd3a294a8",
            "947abecf9233487b8b8a59c54a30863b",
            "05ab613b45a04ff8a17550c9504f60fe",
            "c6004c39d111493eb9a7a87d5113971c",
            "baacb8324310421c9c40725ea93305c1",
            "2317da4c83d146e39ecad5731ed6b7ed",
            "89e7f0d320984a64a4b8bd38c6b857d9",
            "cce45fc859fc4ab68047e831b22a9f63",
            "0238c7a243794525a76e18b434cac162",
            "fbeb4720a25e48f3b2950406fabdd9f3",
            "5efbf896b76f476693ade4ac2f093317",
            "7b7f50f9c9324ac5b58b88262bfe8acd",
            "799ade344d2b486e98b47ad4e19484b3",
            "33bdb1811db14c0abd8d4309fec3dff4",
            "9d5ca2495cc94f469515db35fc0648b2",
            "6c3744f3e5f2470f9432edb3931e54c9",
            "0e2135642b7d4b12bfa718aeb3bc14e6",
            "9619978106074036a6f0a91f8dc0cf2b",
            "54348c82cd2640b9a0e4b459c87c8047",
            "ab401fb8edd74d70a30156cd0eea9747",
            "05669160cbd94c5587927e0a56b5b517",
            "e19f67e12c734f0685cf3d8909bc9eca",
            "edf126b6dc144df3856dacb540839406",
            "f573b358ea654cc3b28767daa144fa97",
            "e56876d0b7fb4f4f9edcfe631f029ff1",
            "c96dc097de09492cb6472faf154eadfb",
            "7ba6601e8c27420f8c54b80dad9c25d6",
            "ed7f94fae0b04494b4836ac1cbac2985",
            "cfef9214938d4f7a93d499736af8d7a9",
            "f70f87a95df042ccbcb234db46121798",
            "955d10b51e9941ccb3004caa46952365",
            "90c757aeb24b4e6fa141f8560a1a77a9",
            "d5bd079097f44cffabfa21a00199a35e",
            "f65fa66219294d2eb5e23c0de21f8d4f",
            "501bdcd287a146118a6d027b1a32bfc3",
            "49b3d47c25574085b40090d2283a4c42",
            "f4bebe12d0b44e1e8188122543fe2f0b",
            "d17e5ce1fb3c490c97a385bacb095f54",
            "7a4ce3281bb7455086cb21a3d6f7f9bd",
            "999021b4ac7143008109dff366a8a3dc",
            "cf34b13742604a70a3934433cd99b16e",
            "10678fff89fb4719937542aa9b0ab3a8",
            "037acfdb903644ee80cd95942cfa6ac3",
            "be698a79b58f45ecae56a9bd16830524",
            "c7224656584f42c2b288b05b74699f3a",
            "b7f78041dc194f8394d3594420455aab",
            "43c26a15781242928db72a51fdb3cae2",
            "43be90287a4a4803b25e78a998fe96ab",
            "db3f6e5b77694dedadda92d0aec7dcf0",
            "81ca2a0f63d741a9bb2be7c2f165b1e8"
          ]
        },
        "outputId": "def2ae53-bc01-4c64-ce62-c61fa0e15736"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Linking Drivers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/260 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b4f1ad42a2049f2b551ef85f4babb1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/257 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89e7f0d320984a64a4b8bd38c6b857d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/741 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9619978106074036a6f0a91f8dc0cf2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfef9214938d4f7a93d499736af8d7a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/436 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "999021b4ac7143008109dff366a8a3dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Resources Loaded.\n",
            "\n",
            "🐢 Running Baseline (ONNX Runtime)...\n",
            "👉 Baseline: 85.67 ms | 36.59% WER\n",
            "\n",
            "🛡️ Building Safe Engine (FP32 Mode)...\n",
            "Building Engine... (This optimizes the graph structure without breaking math)\n",
            "✅ Engine Built!\n",
            "\n",
            "🚀 Running Safe Benchmark...\n",
            "\n",
            "============================================================\n",
            "METRIC               | BASELINE        | OPTIMIZED (FP32)\n",
            "------------------------------------------------------------\n",
            "Latency (ms)         | 85.67           | 54.51          \n",
            "WER (%)              | 36.59           | 109.76         \n",
            "Speedup              | 1.0x            | 1.57           x\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🚀 FINAL SOLUTION: FP32 \"SAFE MODE\" ENGINE\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import ctypes\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "import onnxruntime as ort\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import librosa\n",
        "import io\n",
        "from huggingface_hub import hf_hub_download\n",
        "from transformers import Wav2Vec2Processor\n",
        "from datasets import load_dataset\n",
        "from jiwer import wer\n",
        "\n",
        "# 1. SETUP & LINKING\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"🔧 Linking Drivers...\")\n",
        "try:\n",
        "    libs = glob.glob(\"/usr/local/lib/python*/dist-packages/tensorrt_libs\")[0]\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] += f\":{libs}:/usr/lib64-nvidia\"\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer.so.10\"))\n",
        "    ctypes.CDLL(os.path.join(libs, \"libnvinfer_plugin.so.10\"))\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. DATASET & RESOURCES\n",
        "# -----------------------------------------------------------------------------\n",
        "if not os.path.exists(\"model.onnx\"):\n",
        "    print(\"❌ model.onnx missing! Please check previous steps.\")\n",
        "    exit()\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"ai4bharat/indicwav2vec-hindi\")\n",
        "ds = load_dataset(\"MatrixSpeechAI/Common_voice_hindi_denoised\", split=\"train\", streaming=True).decode(False)\n",
        "test_samples = list(ds.take(20))\n",
        "print(\"✅ Resources Loaded.\")\n",
        "\n",
        "# 3. BASELINE (ONNX)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🐢 Running Baseline (ONNX Runtime)...\")\n",
        "ort_sess = ort.InferenceSession(\"model.onnx\", providers=['CUDAExecutionProvider'])\n",
        "base_times, base_preds, base_truths = [], [], []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    start = time.time()\n",
        "    logits = ort_sess.run(None, {'input_values': input_values})[0]\n",
        "    base_times.append((time.time() - start) * 1000)\n",
        "\n",
        "    pred_ids = np.argmax(logits, axis=-1)[0]\n",
        "    base_preds.append(processor.decode(pred_ids))\n",
        "    base_truths.append(item[\"transcription\"])\n",
        "\n",
        "base_wer = wer(base_truths, base_preds) * 100\n",
        "base_lat = np.mean(base_times)\n",
        "print(f\"👉 Baseline: {base_lat:.2f} ms | {base_wer:.2f}% WER\")\n",
        "\n",
        "# 4. BUILD ENGINE (FP32 ONLY - NO FP16 FLAG)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🛡️ Building Safe Engine (FP32 Mode)...\")\n",
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
        "network = builder.create_network(flag)\n",
        "config = builder.create_builder_config()\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "\n",
        "with open(\"model.onnx\", 'rb') as f:\n",
        "    parser.parse(f.read())\n",
        "\n",
        "profile = builder.create_optimization_profile()\n",
        "profile.set_shape(\"input_values\", (1, 16000), (1, 80000), (4, 160000))\n",
        "config.add_optimization_profile(profile)\n",
        "\n",
        "# CRITICAL CHANGE: WE DO NOT SET THE FP16 FLAG HERE.\n",
        "# This forces TensorRT to use FP32 precision, which is mathematically safe.\n",
        "# We also don't need the \"Antidote\" loop because everything is already FP32.\n",
        "\n",
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 4 * 1024**3)\n",
        "print(\"Building Engine... (This optimizes the graph structure without breaking math)\")\n",
        "plan = builder.build_serialized_network(network, config)\n",
        "\n",
        "if not plan:\n",
        "    print(\"❌ Build Failed!\")\n",
        "    exit()\n",
        "print(\"✅ Engine Built!\")\n",
        "\n",
        "# 5. BENCHMARK ENGINE\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n🚀 Running Safe Benchmark...\")\n",
        "runtime = trt.Runtime(logger)\n",
        "engine = runtime.deserialize_cuda_engine(plan)\n",
        "context = engine.create_execution_context()\n",
        "\n",
        "trt_times, trt_preds = [], []\n",
        "\n",
        "for item in test_samples:\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    # Allocations\n",
        "    context.set_input_shape(\"input_values\", input_values.shape)\n",
        "    d_input = cuda.mem_alloc(input_values.nbytes)\n",
        "    h_output = np.empty((1, input_values.shape[1] // 320, 108), dtype=np.float32)\n",
        "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "\n",
        "    # Inference\n",
        "    cuda.memcpy_htod(d_input, input_values)\n",
        "    start = time.time()\n",
        "    context.execute_v2([int(d_input), int(d_output)])\n",
        "    trt_times.append((time.time() - start) * 1000)\n",
        "    cuda.memcpy_dtoh(h_output, d_output)\n",
        "\n",
        "    # Decode\n",
        "    pred_ids = np.argmax(h_output, axis=-1)[0]\n",
        "    grouped = [x for i, x in enumerate(pred_ids) if i == 0 or x != pred_ids[i-1]]\n",
        "    clean = [x for x in grouped if x != processor.tokenizer.pad_token_id]\n",
        "    trt_preds.append(processor.decode(clean))\n",
        "\n",
        "trt_wer = wer(base_truths, trt_preds) * 100\n",
        "trt_lat = np.mean(trt_times)\n",
        "\n",
        "# 6. REPORT\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{'METRIC':<20} | {'BASELINE':<15} | {'OPTIMIZED (FP32)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Latency (ms)':<20} | {base_lat:<15.2f} | {trt_lat:<15.2f}\")\n",
        "print(f\"{'WER (%)':<20} | {base_wer:<15.2f} | {trt_wer:<15.2f}\")\n",
        "print(f\"{'Speedup':<20} | {'1.0x':<15} | {base_lat/trt_lat:<15.2f}x\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwYFkrpYgVFb",
        "outputId": "4cc25de9-df54-45ca-f632-48acf1038a20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Linking Drivers...\n",
            "✅ Resources Loaded.\n",
            "\n",
            "🐢 Running Baseline (ONNX Runtime)...\n",
            "👉 Baseline: 52.61 ms | 36.59% WER\n",
            "\n",
            "🛡️ Building Safe Engine (FP32 Mode)...\n",
            "Building Engine... (This optimizes the graph structure without breaking math)\n",
            "✅ Engine Built!\n",
            "\n",
            "🚀 Running Safe Benchmark...\n",
            "\n",
            "============================================================\n",
            "METRIC               | BASELINE        | OPTIMIZED (FP32)\n",
            "------------------------------------------------------------\n",
            "Latency (ms)         | 52.61           | 57.47          \n",
            "WER (%)              | 36.59           | 108.94         \n",
            "Speedup              | 1.0x            | 0.92           x\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🚀 MASTER SCRIPT: FRESH EXPORT + BUILD + BENCHMARK\n",
        "# =============================================================================\n",
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorrt as trt\n",
        "import onnxruntime as ort\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import io\n",
        "import time\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from datasets import load_dataset\n",
        "from jiwer import wer\n",
        "\n",
        "# 1. SETUP ENVIRONMENT\n",
        "print(\"🔧 Installing/Verifying Dependencies...\")\n",
        "os.environ[\"LD_LIBRARY_PATH\"] += \":/usr/lib64-nvidia\"\n",
        "\n",
        "# 2. DOWNLOAD PYTORCH MODEL & EXPORT FRESH ONNX\n",
        "print(\"\\n⬇️ Downloading Original PyTorch Model...\")\n",
        "model_id = \"ai4bharat/indicwav2vec-hindi\"\n",
        "try:\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(model_id).to(\"cpu\")\n",
        "    processor = Wav2Vec2Processor.from_pretrained(model_id)\n",
        "    model.eval()\n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to load PyTorch model: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(\"🔄 Generating Fresh ONNX (Opset 17)...\")\n",
        "dummy_input = torch.randn(1, 16000) # 1 second audio\n",
        "onnx_path = \"model_fresh.onnx\"\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        export_params=True,\n",
        "        opset_version=17,  # CRITICAL: Opset 17 fixes the LayerNorm bug\n",
        "        do_constant_folding=True,\n",
        "        input_names=['input_values'],\n",
        "        output_names=['logits'],\n",
        "        dynamic_axes={\n",
        "            'input_values': {0: 'batch_size', 1: 'sequence_length'},\n",
        "            'logits': {0: 'batch_size', 1: 'sequence_length'}\n",
        "        }\n",
        "    )\n",
        "print(f\"✅ Fresh ONNX Created: {onnx_path}\")\n",
        "\n",
        "# 3. BUILD TENSORRT ENGINE (SAFE MODE)\n",
        "print(\"\\n🛡️ Building TensorRT Engine (FP32)...\")\n",
        "logger = trt.Logger(trt.Logger.WARNING)\n",
        "builder = trt.Builder(logger)\n",
        "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
        "config = builder.create_builder_config()\n",
        "parser = trt.OnnxParser(network, logger)\n",
        "\n",
        "with open(onnx_path, 'rb') as f:\n",
        "    if not parser.parse(f.read()):\n",
        "        print(\"❌ ONNX Parse Failed\")\n",
        "        for e in range(parser.num_errors): print(parser.get_error(e))\n",
        "        exit()\n",
        "\n",
        "# Setup Profile (Crucial for correct execution)\n",
        "profile = builder.create_optimization_profile()\n",
        "profile.set_shape(\"input_values\", (1, 16000), (1, 80000), (4, 160000))\n",
        "config.add_optimization_profile(profile)\n",
        "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 4 * 1024**3)\n",
        "\n",
        "# Build\n",
        "plan = builder.build_serialized_network(network, config)\n",
        "if not plan:\n",
        "    print(\"❌ Engine Build Failed!\")\n",
        "    exit()\n",
        "print(\"✅ Engine Built Successfully!\")\n",
        "\n",
        "# 4. BENCHMARK (With Proper Binding Checks)\n",
        "print(\"\\n🚀 Running Benchmark...\")\n",
        "\n",
        "# Load Resources\n",
        "ds = load_dataset(\"MatrixSpeechAI/Common_voice_hindi_denoised\", split=\"train\", streaming=True).decode(False)\n",
        "test_samples = list(ds.take(20))\n",
        "\n",
        "# Setup Runtime\n",
        "runtime = trt.Runtime(logger)\n",
        "engine = runtime.deserialize_cuda_engine(plan)\n",
        "context = engine.create_execution_context()\n",
        "\n",
        "# Resolve Bindings\n",
        "tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]\n",
        "input_name = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.INPUT][0]\n",
        "output_name = [n for n in tensor_names if engine.get_tensor_mode(n) == trt.TensorIOMode.OUTPUT][0]\n",
        "\n",
        "# Setup Baseline\n",
        "ort_sess = ort.InferenceSession(onnx_path, providers=['CUDAExecutionProvider'])\n",
        "\n",
        "base_times, trt_times = [], []\n",
        "base_preds, trt_preds = [], []\n",
        "truths = []\n",
        "\n",
        "for i, item in enumerate(test_samples):\n",
        "    # Prepare Input\n",
        "    audio, _ = librosa.load(io.BytesIO(item[\"audio\"][\"bytes\"]), sr=16000)\n",
        "    raw_input = processor(audio, sampling_rate=16000, return_tensors=\"np\").input_values\n",
        "\n",
        "    # ⚠️ CRITICAL: Strict shape checks to prevent crashing\n",
        "    seq_len = raw_input.shape[1]\n",
        "    if seq_len < 16000 or seq_len > 160000:\n",
        "        continue # Skip samples that violate the TensorRT Profile\n",
        "\n",
        "    input_values = np.ascontiguousarray(raw_input).astype(np.float32)\n",
        "    truths.append(item[\"transcription\"])\n",
        "\n",
        "    # Run Baseline\n",
        "    start = time.time()\n",
        "    logits = ort_sess.run(None, {'input_values': input_values})[0]\n",
        "    base_times.append((time.time() - start) * 1000)\n",
        "    pred_ids = np.argmax(logits, axis=-1)[0]\n",
        "    base_preds.append(processor.decode([x for x in pred_ids if x != processor.tokenizer.pad_token_id]))\n",
        "\n",
        "    # Run TensorRT\n",
        "    context.set_input_shape(input_name, input_values.shape)\n",
        "    d_input = cuda.mem_alloc(input_values.nbytes)\n",
        "    out_shape = (1, input_values.shape[1] // 320, 108)\n",
        "    h_output = np.zeros(out_shape, dtype=np.float32)\n",
        "    d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(d_input, input_values)\n",
        "    context.set_tensor_address(input_name, int(d_input))\n",
        "    context.set_tensor_address(output_name, int(d_output))\n",
        "\n",
        "    start = time.time()\n",
        "    context.execute_async_v3(stream_handle=0)\n",
        "    cuda.Context.synchronize()\n",
        "    trt_times.append((time.time() - start) * 1000)\n",
        "\n",
        "    cuda.memcpy_dtoh(h_output, d_output)\n",
        "\n",
        "    # Decode\n",
        "    pred_ids = np.argmax(h_output, axis=-1)[0]\n",
        "    grouped = [x for k, x in enumerate(pred_ids) if k == 0 or x != pred_ids[k-1]]\n",
        "    trt_preds.append(processor.decode([x for x in grouped if x != processor.tokenizer.pad_token_id]))\n",
        "\n",
        "    if i % 5 == 0: print(f\"   Processed {i+1}...\")\n",
        "\n",
        "# 5. REPORT\n",
        "base_wer = wer(truths, base_preds) * 100\n",
        "trt_wer = wer(truths, trt_preds) * 100\n",
        "base_lat = np.mean(base_times)\n",
        "trt_lat = np.mean(trt_times)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"{'METRIC':<20} | {'BASELINE (ONNX)':<15} | {'OPTIMIZED (TRT)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Latency (ms)':<20} | {base_lat:<15.2f} | {trt_lat:<15.2f}\")\n",
        "print(f\"{'WER (%)':<20} | {base_wer:<15.2f} | {trt_wer:<15.2f}\")\n",
        "print(f\"{'Speedup':<20} | {'1.0x':<15} | {base_lat/trt_lat:<15.2f}x\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "gL9lXK93jyuh",
        "outputId": "e162ed8f-98ce-49df-cc8b-e3d9c05f752c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Installing/Verifying Dependencies...\n",
            "\n",
            "⬇️ Downloading Original PyTorch Model...\n",
            "🔄 Generating Fresh ONNX (Opset 17)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'onnxscript'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-606242246.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     torch.onnx.export(\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, verbose, input_names, output_names, opset_version, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, export_params, keep_initializers_as_inputs, dynamic_axes, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdynamo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExportedProgram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/exporter/_compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_constants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0monnx_constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_import\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnxscript_apis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnxscript_ir\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from torch.onnx._internal.exporter import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0m_core\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/onnx/_internal/exporter/_core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnxscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnxscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnxscript\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxscript'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJKzjhuDkE5m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}